# Тема лабораторной работы "Разработка системы автоматического перевода с использованием моделей нейронного машинного перевода."

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/18fXF_kcnEd-QSQFHLqXb4wHSIuJ8xgEL#scrollTo=QbCkRm58uep4)

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1tBRjSFcwfnsshk0CVZfjfsN6--QBy75E#scrollTo=kTIGvJUxfp5S)

## Описание проекта

Этот проект посвящен разработке системы автоматического перевода с использованием современных моделей нейронного машинного перевода. Целью данного проекта является создание системы, способной переводить тексты с высокой точностью и эффективностью.

## Рассмотрим этапы создания модели

1. **Подготовка данных:**
   - Надо собрать пары текстов на двух языках для обучающего набора.
   - Затем нужно разделить данные на обучающий и тестовый наборы.

2. **Токенизация:**
   - Нужно преобразовать текст в последовательности токенов для лучшего понимания структуры языка.

3. **Энкодер:**
   - Энкодер используется для преобразования исходного текста в вектор фиксированной длины, представляющий семантику текста.
   - Можно использовать RNN или трансформеры в роли энкодера.

4. **Декодер:**
   - Декодер генерирует целевой текст из вектора, полученного от энкодера.
   - На каждом шаге предсказывается следующий токен с использованием контекста и предыдущих предсказаний.

5. **Обучение:**
   - Модель обучается на обучающем наборе с использованием функции потерь.
   - Обновления весов модели происходят в процессе обратного распространения ошибки.

## Эндокодер/Декодер

- **Энкодер:**
   - Принимает входной текст и преобразует его в вектор фиксированной длины.
   - Каждое слово представляется вектором (word embedding) и проходит через слои энкодера.

- **Декодер:**
   - Получает вектор от энкодера и генерирует целевой текст.
   - Использует механизм внимания для фокусировки на различных частях входного текста в разные моменты времени.

## Использованные Библиотеки и Инструменты

Для выполнения этой работы я рассмотрел два случая, использование готовой модели и использование встроенной библиотеки с переводом. Рассмотрим каждую из них

### Система на основе модели.
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/18fXF_kcnEd-QSQFHLqXb4wHSIuJ8xgEL#scrollTo=QbCkRm58uep4)

Для начала работы, по ссылке выше нужно установить библиотеки ниже

1. **Готовая модель:**
   - Библиотеки: langdetect, transformers, sentencepiece
   - Установка: 
     ```bash
     !pip install langdetect
     !pip install transformers
     !pip install sentencepiece
     ```
   - Инициализация:
     ```python
     from transformers import pipeline
     src = "en"
     dst = "de"
     task_name = f"translation_{src}_to_{dst}"
     model_name = f"Helsinki-NLP/opus-mt-{src}-{dst}"
     translator  = pipeline(task_name, model=model_name, tokenizer=model_name)

  Результат работы по переводу с английского на русский, после выполнения остальных запусков в коде
  ![Пример результата модели](https://github.com/Opetrek/Labwork1/blob/main/Lab-work2/%D0%9B%D0%B0%D0%B1.%D1%80%D0%B0%D0%B12%20-%20%D0%BF%D0%B5%D1%80%D0%B5%D0%B2%D0%BE%D0%B4%20%D1%82%D0%B5%D0%BA%D1%81%D1%82%D0%B0%20%D1%81%20%D0%BF%D0%BE%D0%BC%D0%BE%D1%89%D0%B8%20%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8.png)

### Система на основе встроенной библиотеки Google Translate.

1. **Установка библиотеки:**
   - Выполните команду установки с помощью pip:
     ```bash
     pip install googletrans==3.1.0a0
     ```

2. **Пример кода:**
   - Вставьте следующий код в ваш проект:
     ```python
     from googletrans import Translator, constants
     from pprint import pprint

     # Инициализация объекта Translator
     translator = Translator()
     
     # Пример использования
     original_text = "Hello, how are you?"
     destination_language = "es"
     
     # Перевод текста
     translated_text = translator.translate(original_text, dest=destination_language).text
     
     # Вывод результата
     pprint({
         "Оригинальный текст": original_text,
         "Переведенный текст": translated_text,
         "Исходный язык": constants.LANGUAGES[translator.detect(original_text).lang],
         "Целевой язык": constants.LANGUAGES[destination_language]
     })
     ```

Так же я решил сравнить перевод от встроенной библиотеки Google Translate с использованной моделью.

![Пример результата модели](https://github.com/Opetrek/Labwork1/blob/main/Lab-work2/%D0%9B%D0%B0%D0%B1.%D1%80%D0%B0%D0%B12%20-%20%D0%BF%D0%B5%D1%80%D0%B5%D0%B2%D0%BE%D0%B4%20%D1%82%D0%B5%D0%BA%D1%81%D1%82%D0%B0%20%D1%81%20%D0%BF%D0%BE%D0%BC%D0%BE%D1%89%D0%B8%20%D0%B3%D1%83%D0%B3%D0%BB%20%D0%BF%D0%B5%D1%80%D0%B5%D0%B2%D0%BE%D0%B4%D1%87%D0%B8%D0%BA%D0%B0.png)

Как видно на фотографиях, получились достаточно неплохой результат для предобученной модели по сравнению со встроенной библиотекой google translate.
При сравнении качества перевода между предобученной моделью и библиотекой Google Translate было замечено небольшое отклонение. Это может быть обусловлено несколькими факторами:

1. **Различия в Моделях:**
   - Предобученные модели могут быть обучены на различных корпусах текста, что может повлиять на их способность к точному переводу. Модели могут иметь свои сильные и слабые стороны в зависимости от данных, на которых они были обучены.

2. **Обработка Различных Языков:**
   - Разные модели и библиотеки могут обрабатывать различные языки по-разному. Возможны небольшие отклонения в качестве перевода для конкретных языков из-за особенностей их обработки.
